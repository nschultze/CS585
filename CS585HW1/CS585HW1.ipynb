{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cfbd0c8-48c1-4773-ad47-f0bf80f9b885",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nikolausschultze/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#NLTK setup - uncomment and run first time you import NLTK\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from csv import QUOTE_NONE\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import statistics\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea894a5b-fb50-4dab-b737-83efa4a0c351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hide new secretions from the parental units</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contains no wit , only labored gags</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that loves its characters and communicates som...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label\n",
       "0       hide new secretions from the parental units       0\n",
       "1               contains no wit , only labored gags       0\n",
       "2  that loves its characters and communicates som...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sst = pd.read_csv(\"SST-2/train.tsv\",delimiter=\"\\t\")\n",
    "df_sst.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a3e2a5b-4d6b-4610-b63d-e3b85b412216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What came into force after the new constitutio...</td>\n",
       "      <td>As of that day, the new constitution heralding...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the first major city in the stream of ...</td>\n",
       "      <td>The most important tributaries in this area ar...</td>\n",
       "      <td>not_entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What is the minimum required if you want to te...</td>\n",
       "      <td>In most provinces a second Bachelor's Degree s...</td>\n",
       "      <td>not_entailment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                           question  \\\n",
       "0      0  What came into force after the new constitutio...   \n",
       "1      1  What is the first major city in the stream of ...   \n",
       "2      2  What is the minimum required if you want to te...   \n",
       "\n",
       "                                            sentence           label  \n",
       "0  As of that day, the new constitution heralding...      entailment  \n",
       "1  The most important tributaries in this area ar...  not_entailment  \n",
       "2  In most provinces a second Bachelor's Degree s...  not_entailment  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qnli = pd.read_csv(\"QNLI//dev.tsv\",delimiter=\"\\t\",quoting=QUOTE_NONE)\n",
    "df_qnli.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e4771d3-87fa-4930-9067-2197e05dcffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['really', ',', 'save', 'your', 'disgust', 'and', 'your', 'indifference']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demo - split a sentence into tokens\n",
    "some_sentence = df_sst.sentence.iloc[-100]\n",
    "word_tokenize(some_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47b20db",
   "metadata": {},
   "source": [
    "Problem 1 – Representing English Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7537f2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hide', 'new', 'secretions', 'from', 'the', 'parental', 'units', 'contains', 'no', 'wit']\n"
     ]
    }
   ],
   "source": [
    "tokenizedSST = []\n",
    "for i in df_sst.index:\n",
    "    sentenceSST = df_sst.sentence.iloc[i]\n",
    "    sentenceSST = sentenceSST.lower()\n",
    "    tokenizedSST.extend(word_tokenize(sentenceSST))\n",
    "\n",
    "print(tokenizedSST[:10])\n",
    "#print(len(tokenizedSST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d1b740a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['as', 'of', 'that', 'day', ',', 'the', 'new', 'constitution', 'heralding', 'the']\n"
     ]
    }
   ],
   "source": [
    "tokenizedQNLI = []\n",
    "for i in df_qnli.index:\n",
    "    sentenceQNLI = df_qnli.sentence.iloc[i]\n",
    "    sentenceQNLI = sentenceQNLI.lower()\n",
    "    tokenizedQNLI.extend(word_tokenize(sentenceQNLI))\n",
    "\n",
    "print(tokenizedQNLI[:10])\n",
    "#print(len(tokenizedQNLI))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d88848",
   "metadata": {},
   "source": [
    "Problem 2 – Word Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c2998af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordProbabilityFunction(data):\n",
    "    dict = {}\n",
    "    sum = 0\n",
    "    for i in data:\n",
    "        if i not in dict:\n",
    "            count = data.count(i) / len(data)\n",
    "            dict[i] = count\n",
    "            sum = sum + count\n",
    "\n",
    "    return dict, sum\n",
    "    #print(len(data))\n",
    "\n",
    "#choose the word, go through the dataframe and count how many times that word appears in the dataframe, return the word and the count into the dict, move onto the next word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b2a5c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST Dictionary first 10 world probabilities : {'hide': 2.208187960959237e-05, 'new': 0.0010788575466400842, 'secretions': 4.73183134491265e-06, 'from': 0.0029321581567308725, 'the': 0.042909823912782884, 'parental': 1.2618216919767068e-05, 'units': 9.4636626898253e-06, 'contains': 3.627737364433032e-05, 'no': 0.0016671819105242237, 'wit': 0.0003233418085690311}\n",
      "Probability Distribution Sum:  0.9999999999998211\n"
     ]
    }
   ],
   "source": [
    "dictSST, sumSST = wordProbabilityFunction(tokenizedSST)\n",
    "N = 10\n",
    "outputSST = dict(itertools.islice(dictSST.items(), N))\n",
    "print(\"SST Dictionary first 10 world probabilities : \" + str(outputSST))\n",
    "#print(\"SST Dictionary: \", dictSST)\n",
    "print(\"Probability Distribution Sum: \", sumSST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e1f5052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QNLI Dictionary first 10 world probabilities : {'as': 0.007995208689483538, 'of': 0.03309725662584749, 'that': 0.007268371535894126, 'day': 0.00037214062263777925, ',': 0.05396039028247799, 'the': 0.06861342729884055, 'new': 0.0017153356824710136, 'constitution': 8.14057612020142e-05, 'heralding': 1.7444091686145903e-05, 'second': 0.00044773168661107815}\n",
      "Probability Distribution Sum:  0.9999999999998687\n"
     ]
    }
   ],
   "source": [
    "dictQNLI, sumQNLI = wordProbabilityFunction(tokenizedQNLI)\n",
    "N = 10\n",
    "outputQNLI = dict(itertools.islice(dictQNLI.items(), N))\n",
    "print(\"QNLI Dictionary first 10 world probabilities : \" + str(outputQNLI))\n",
    "print(\"Probability Distribution Sum: \", sumQNLI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ec43d8",
   "metadata": {},
   "source": [
    "Problem 3 – Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53f879c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropyFunction(dict):\n",
    "    entropy = 0\n",
    "    for value in dict:\n",
    "        pX = dict[value]\n",
    "        temp = pX * math.log2(pX)\n",
    "        entropy = entropy + temp\n",
    "\n",
    "    entropy = entropy * -1\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d32ab28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST's Entropy:  10.079162530566823\n"
     ]
    }
   ],
   "source": [
    "entropySST = entropyFunction(dictSST)\n",
    "print(\"SST's Entropy: \", entropySST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2e7f6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QNLI's Entropy:  10.037404792966129\n"
     ]
    }
   ],
   "source": [
    "entropyQNLI = entropyFunction(dictQNLI)\n",
    "print(\"QNLI's Entropy: \", entropyQNLI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd86406",
   "metadata": {},
   "source": [
    "Problem 4 – KL Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c3a6013",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KL Divergence = - sum of P(X = x) * log_2(Q(X = x)/ P(X = x)))\n",
    "def klDivergenceFunction(p, q):\n",
    "    klDivergence = 0\n",
    "    averageProbability = statistics.mean(list(p.values()))\n",
    "    for value in p:\n",
    "        if value in q:\n",
    "            pX = p[value]\n",
    "            qX = q[value]\n",
    "            temp = pX * math.log2((qX) / (pX))\n",
    "            klDivergence = klDivergence + temp\n",
    "        else:\n",
    "            #pass\n",
    "            klDivergence = klDivergence + (pX * math.log2((averageProbability) / (pX)))\n",
    "\n",
    "    klDivergence = klDivergence *- 1\n",
    "    return klDivergence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53d37bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergence where SST is P(X) and QNLI is Q(X):  2.4303639551580383\n"
     ]
    }
   ],
   "source": [
    "klDivergenceSST = klDivergenceFunction(dictSST, dictQNLI)\n",
    "print(\"KL Divergence where SST is P(X) and QNLI is Q(X): \", klDivergenceSST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f02695ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergence where QNLI is P(X) and SST is Q(X):  1.5924811708541398\n"
     ]
    }
   ],
   "source": [
    "klDivergenceQNLI = klDivergenceFunction(dictQNLI, dictSST)\n",
    "print(\"KL Divergence where QNLI is P(X) and SST is Q(X): \", klDivergenceQNLI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ff2404",
   "metadata": {},
   "source": [
    "Problem 5 – Entropy Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6a7e47",
   "metadata": {},
   "source": [
    "Moview review by Rick Bentley on Aug 9, 2023 from https://www.rottentomatoes.com/m/top_gun_maverick/reviews?intcmp=rt-what-to-know_read-critics-reviews. Review: \"It is all of the flying sequences that are shot in such a way that it makes the moviegoer feel like they are a passenger that gives the movie its energy and makes it so much fun.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c76c3145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it', 'is', 'all', 'of', 'the', 'flying', 'sequences', 'that', 'are', 'shot', 'in', 'such', 'a', 'way', 'that', 'it', 'makes', 'the', 'moviegoer', 'feel', 'like', 'they', 'are', 'a', 'passenger', 'that', 'gives', 'the', 'movie', 'its', 'energy', 'and', 'makes', 'it', 'so', 'much', 'fun']\n"
     ]
    }
   ],
   "source": [
    "review = [\"It\", \"is\", \"all\", \"of\", \"the\", \"flying\", \"sequences\", \"that\", \"are\", \"shot\", \"in\", \"such\", \"a\", \"way\", \"that\", \"it\", \"makes\", \"the\", \"moviegoer\", \"feel\", \"like\", \"they\", \"are\", \"a\", \"passenger\", \"that\", \"gives\", \"the\", \"movie\", \"its\", \"energy\", \"and\", \"makes\", \"it\", \"so\", \"much\", \"fun\"]\n",
    "review = list(map(str.lower, review))\n",
    "print(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1f6821b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entropy Rate = (1 / n) * sum of p(x_1n)log(p(x_1n))\n",
    "def entropyRateFunction(dict, review):\n",
    "    entropy = 0\n",
    "    n = len(review)\n",
    "    uniqueWords = []\n",
    "    averageProbability = statistics.mean(list(dict.values()))\n",
    "    for value in review:\n",
    "        if value in dict:\n",
    "            pX = dict[value]\n",
    "            temp = pX * math.log2(pX)\n",
    "            entropy = entropy + temp\n",
    "        else:\n",
    "            entropy = entropy + (averageProbability * math.log2(averageProbability))\n",
    "            uniqueWords.append(value)\n",
    "    entropy = entropy * -1\n",
    "    entropyRate = entropy / n\n",
    "    print(uniqueWords)\n",
    "    return entropy, entropyRate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f999ebb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['passenger']\n",
      "Entropy for SST is:  2.135225952504406\n",
      "Entropy Rate for SST is:  0.05770880952714611\n"
     ]
    }
   ],
   "source": [
    "entropySST, entropyRateSST = entropyRateFunction(dictSST, review)\n",
    "print(\"Entropy for SST is: \", entropySST)\n",
    "print(\"Entropy Rate for SST is: \", entropyRateSST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11280901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['moviegoer', 'fun']\n",
      "Entropy for QNLI is:  1.8970224089161896\n",
      "Entropy Rate for QNLI is:  0.051270875916653774\n"
     ]
    }
   ],
   "source": [
    "entropyQNLI, entropyRateQNLI = entropyRateFunction(dictQNLI, review)\n",
    "print(\"Entropy for QNLI is: \", entropyQNLI)\n",
    "print(\"Entropy Rate for QNLI is: \", entropyRateQNLI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89ab688",
   "metadata": {},
   "source": [
    "PROBLEM 6 – Observed Entropy Rate (Answer in Blackboard)\n",
    "Refer to your results from Problem 5. Which distribution gives you the lowest entropy rate for your\n",
    "movie review? Does this match what you expected? Why or why not?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a822c72c",
   "metadata": {},
   "source": [
    "The distribution that gives me the lowest entropy rate for the movie review is QNLI. I  expected this because when we calculated the entropy for both dictionaries, the entropy for the QNLI dictionary was lower than the entropy for the SST dictionary and when we calculated the entropy based on the movie review, the entropy was lower for QNLI than SST. SST was also significantly bigger than QNLI meaning that there are more words which could lower the probability for each word. But that would also decrease the chances of a word in the review being in QNLI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c802e9d",
   "metadata": {},
   "source": [
    "PROBLEM 7 – Zero probabilities (Answer in Blackboard)\n",
    "Problem 5 required that you handle “zero probabilities” cases, where a token occurred in one dataset but not the other. How did you handle these tokens? (Hint: Dropping the word from both probability distributions is not an ideal solution)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e797eb",
   "metadata": {},
   "source": [
    "I handled zero probabilities by first calculating the average word probability for the dataset by taking the mean of the list of all the values from the dictionary.  I then went through the review checking to see if the word was also in the dictionary. If it was, I added the probability for that word to entropyRate which is the sum of all the word probabilities. If the word was not in the dictionary, I added the average word probability for the current dictionary to the sum. After iterating through the entire review, I took the sum and divided by n to get the entropy rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d37d48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
